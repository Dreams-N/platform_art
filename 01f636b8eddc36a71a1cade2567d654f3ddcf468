Revision: 01f636b8eddc36a71a1cade2567d654f3ddcf468
Patch-set: 1
File: runtime/arch/arm64/quick_entrypoints_arm64.S

1452:0-1464:21
Mon Oct 26 13:58:15 2015 +0000
Author: Serban Constantinescu <1072549@85c56323-6fa9-3386-8a01-6480fb634889>
UUID: b6b19df3_b73b8890
Bytes: 97
Load aquire seems a better solution to me. Alternatively DMB ISHLD after the ldr would also work.

1452:0-1464:21
Mon Oct 26 18:27:44 2015 +0000
Author: Hiroshi Yamauchi <1022530@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: b6b19df3_b73b8890
UUID: f6ceb575_2ad45e1b
Bytes: 161
My measurement indicated this 'fake dependence' approach was faster than the dmb ishld + dmb ishst approach (by ~10-20% on arm32 at least). Better in what sense?

1452:0-1464:21
Tue Oct 27 11:20:46 2015 +0000
Author: Serban Constantinescu <1072549@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: f6ceb575_2ad45e1b
UUID: f69a3588_e1924696
Bytes: 347
Load acquire and store release have a finer granularity when compared to their ldr/str + dmbs equivalents, regarding memory ordering.

Future CPU implementations might decide to exploit this and to optimise even further the acquire-release path.

Therefore the acuqire-release path seems better to me.

For curiosity what have you measure this on?

1452:0-1464:21
Tue Oct 27 17:26:43 2015 +0000
Author: Hiroshi Yamauchi <1022530@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: f69a3588_e1924696
UUID: 96df3923_dbccacc1
Bytes: 369
Serban, there are three things we are comparing here. 1) ldr + the 'fake dependence' eor/add + no dmb (as is in this CL currently), 2) ldra, 3) ldr+dmb ishld. Are you saying that 2) is better than 3) or that 2) and 3) are better than 1) or something else?

The measurement was on a Nexus 5, which uses the arm32 version of this code, where 1) was faster than 3) for me.

1452:0-1464:21
Thu Oct 29 11:50:59 2015 +0000
Author: Serban Constantinescu <1072549@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: 96df3923_dbccacc1
UUID: b6199d10_375f3851
Bytes: 468
Sorry for the confusion. What I am saying is that 2) should always be preferred over 3), and as I mentioned future CPU versions will probably optimise this even further.

The comparison between 1) and 2) is debatable. The best way of comparing is writing a very directed ubenchmark, and even so there are CPU variants out there that decided to implement 2) as 3) for simplicity.

Therefore I think 1), the variant that you are currently using is the best in this case.

1470
Mon Oct 26 13:58:15 2015 +0000
Author: Serban Constantinescu <1072549@85c56323-6fa9-3386-8a01-6480fb634889>
UUID: 36920d67_6b7e819d
Bytes: 251
#if THREAD_LOCAL_ALLOC_STACK_END_OFFSET != (THREAD_LOCAL_ALLOC_STACK_TOP_OFFSET + __SIZEOF_POINTER__)
#error "The assumption below that we can use ldrd from the STACK_TOP is invalid."
#endif

ldrd, x3, x4, [xSELF, #THREAD_LOCAL_ALLOC_STACK_TOP_OFFSET]

1470
Mon Oct 26 18:27:44 2015 +0000
Author: Hiroshi Yamauchi <1022530@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: 36920d67_6b7e819d
UUID: 76d48537_70d04e53
Bytes: 31
Can ldrd load two 64-bit words?

1470
Mon Oct 26 18:50:30 2015 +0000
Author: Andreas Gampe <1041833@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: 76d48537_70d04e53
UUID: 16b509da_f4d9787c
Bytes: 26
Serban probably meant ldp.

1470
Mon Oct 26 22:15:44 2015 +0000
Author: Hiroshi Yamauchi <1022530@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: 16b509da_f4d9787c
UUID: b6d8bd3b_99f94bed
Bytes: 250
ldp does not seems to work as the offset is out of the supported range.

art/runtime/arch/arm64/quick_entrypoints_arm64.S:1474:23: error: index must be a multiple of 8 in range [-512, 504].
    ldp x3, x4, [x19, #(((128 + 150 * 8) + 3 * 8) + 34 * 8)]

1470
Tue Oct 27 11:20:46 2015 +0000
Author: Serban Constantinescu <1072549@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: b6d8bd3b_99f94bed
UUID: 56b5c1f6_5c4f9d53
Bytes: 40
I did mean ldp. Sorry for the confusion.

1531
Mon Oct 26 13:58:15 2015 +0000
Author: Serban Constantinescu <1072549@85c56323-6fa9-3386-8a01-6480fb634889>
UUID: 36b04d09_5b3e83f2
Bytes: 47
And with the above dmb this can be an dmb ishst

1531
Wed Oct 28 19:01:33 2015 +0000
Author: Hans Boehm <1042828@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: 36b04d09_5b3e83f2
UUID: 96cad9dc_e9d931e1
Bytes: 317
That's what Hiroshi started with.  This does seem faster for now, in a place where it matters.  We should probably revisit once we have a faster acquire load implementation.

I think we all agree that the acquire load would be cleaner. But in spite of my reputation for hating performance :-), I think that wins here.


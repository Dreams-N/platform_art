Revision: 01f636b8eddc36a71a1cade2567d654f3ddcf468
Patch-set: 1
File: runtime/arch/arm64/quick_entrypoints_arm64.S

1458:65-1461:72
Mon Nov 02 09:08:38 2015 +0000
Author: Nicolas Geoffray <1038443@85c56323-6fa9-3386-8a01-6480fb634889>
UUID: 569941f8_bffd9322
Bytes: 93
So this is a compiler issue, not a processor cache in the presence of multicore issue, right?

1458:65-1461:72
Mon Nov 02 10:17:52 2015 +0000
Author: Serban Constantinescu <1072549@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: 569941f8_bffd9322
UUID: 167c2956_85ede4e6
Bytes: 320
No it is not a compiler issues. It is a fake dependency between x3 and x2 that prevents the CPU from reordering the
#MIRROR_CLASS_STATUS_OFFSET and #MIRROR_CLASS_ACCESS_FLAGS_OFFSET loads to #MIRROR_CLASS_ACCESS_FLAGS_OFFSET and #MIRROR_CLASS_STATUS_OFFSET.

As mentioned in the comments a load-acquire would be cleaner.

1458:65-1461:72
Mon Nov 02 10:27:43 2015 +0000
Author: Nicolas Geoffray <1038443@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: 167c2956_85ede4e6
UUID: b688bda5_02ae2c05
Bytes: 864
So for my understanding, we worry about the situation:

Thread1 (executing this stub): load the access flags
Thread2 (executing the clinit): set the flags and initialize the class.
Thread1: load the status flags

Right?

But by loading the access flags, we have loaded into our CPU cache the page where the class is. So the read of the status flag will go through the cache. Still correct?

So I understand that if the threads have run on the same CPU, it is definitely a CPU reordering problem.

I'm also curious what happens if we do this dependency trick, but Thread1 and Thread2 run on two different cpus. Say Thread1 loads the status flag, but the access flags is not on the same page (is that possible?), but has been loaded somehow before in our cpu cache. Could it be that even after reading the status flag, reading the access flag could still be garbage?

1458:65-1461:72
Mon Nov 02 11:57:58 2015 +0000
Author: Vladimir Marko <1018108@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: b688bda5_02ae2c05
UUID: 167c2956_c548cca1
Bytes: 845
This situation we're concerned about is this:

  Thread 1 executing <clinit>():
    - [11] replace old access flags with new access flags,
    - [12] replace old status with new status,
  Thread 2 executing this stub:
    - [21] read status: reads new status,
    - [22] read access flags: may read old access flags!

Without proper synchronization the writes by one thread may become visible to another thread (executing on another core) in a different order. To prevent this memory visibility reordering we would normally give [12] release semantics (which we do) and give [21] acquire semantics. The CPU-specific hack here is a fake dependency between [21] and [22] that makes up for the absence of the acquire semantics on [21].

(Note that the status and access flags are not necessarily in the same page, much less in the same cache line.)

1452:0-1464:21
Mon Oct 26 13:58:15 2015 +0000
Author: Serban Constantinescu <1072549@85c56323-6fa9-3386-8a01-6480fb634889>
UUID: b6b19df3_b73b8890
Bytes: 97
Load aquire seems a better solution to me. Alternatively DMB ISHLD after the ldr would also work.

1452:0-1464:21
Mon Oct 26 18:27:44 2015 +0000
Author: Hiroshi Yamauchi <1022530@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: b6b19df3_b73b8890
UUID: f6ceb575_2ad45e1b
Bytes: 161
My measurement indicated this 'fake dependence' approach was faster than the dmb ishld + dmb ishst approach (by ~10-20% on arm32 at least). Better in what sense?

1452:0-1464:21
Tue Oct 27 11:20:46 2015 +0000
Author: Serban Constantinescu <1072549@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: f6ceb575_2ad45e1b
UUID: f69a3588_e1924696
Bytes: 347
Load acquire and store release have a finer granularity when compared to their ldr/str + dmbs equivalents, regarding memory ordering.

Future CPU implementations might decide to exploit this and to optimise even further the acquire-release path.

Therefore the acuqire-release path seems better to me.

For curiosity what have you measure this on?

1452:0-1464:21
Tue Oct 27 17:26:43 2015 +0000
Author: Hiroshi Yamauchi <1022530@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: f69a3588_e1924696
UUID: 96df3923_dbccacc1
Bytes: 369
Serban, there are three things we are comparing here. 1) ldr + the 'fake dependence' eor/add + no dmb (as is in this CL currently), 2) ldra, 3) ldr+dmb ishld. Are you saying that 2) is better than 3) or that 2) and 3) are better than 1) or something else?

The measurement was on a Nexus 5, which uses the arm32 version of this code, where 1) was faster than 3) for me.

1452:0-1464:21
Thu Oct 29 11:50:59 2015 +0000
Author: Serban Constantinescu <1072549@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: 96df3923_dbccacc1
UUID: b6199d10_375f3851
Bytes: 468
Sorry for the confusion. What I am saying is that 2) should always be preferred over 3), and as I mentioned future CPU versions will probably optimise this even further.

The comparison between 1) and 2) is debatable. The best way of comparing is writing a very directed ubenchmark, and even so there are CPU variants out there that decided to implement 2) as 3) for simplicity.

Therefore I think 1), the variant that you are currently using is the best in this case.

1452:0-1464:21
Thu Oct 29 17:59:16 2015 +0000
Author: Hiroshi Yamauchi <1022530@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: b6199d10_375f3851
UUID: 769c85d8_07710a0d
Bytes: 15
Agreed. Thanks.

1470
Mon Oct 26 13:58:15 2015 +0000
Author: Serban Constantinescu <1072549@85c56323-6fa9-3386-8a01-6480fb634889>
UUID: 36920d67_6b7e819d
Bytes: 251
#if THREAD_LOCAL_ALLOC_STACK_END_OFFSET != (THREAD_LOCAL_ALLOC_STACK_TOP_OFFSET + __SIZEOF_POINTER__)
#error "The assumption below that we can use ldrd from the STACK_TOP is invalid."
#endif

ldrd, x3, x4, [xSELF, #THREAD_LOCAL_ALLOC_STACK_TOP_OFFSET]

1470
Mon Oct 26 18:27:44 2015 +0000
Author: Hiroshi Yamauchi <1022530@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: 36920d67_6b7e819d
UUID: 76d48537_70d04e53
Bytes: 31
Can ldrd load two 64-bit words?

1470
Mon Oct 26 18:50:30 2015 +0000
Author: Andreas Gampe <1041833@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: 76d48537_70d04e53
UUID: 16b509da_f4d9787c
Bytes: 26
Serban probably meant ldp.

1470
Mon Oct 26 22:15:44 2015 +0000
Author: Hiroshi Yamauchi <1022530@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: 16b509da_f4d9787c
UUID: b6d8bd3b_99f94bed
Bytes: 250
ldp does not seems to work as the offset is out of the supported range.

art/runtime/arch/arm64/quick_entrypoints_arm64.S:1474:23: error: index must be a multiple of 8 in range [-512, 504].
    ldp x3, x4, [x19, #(((128 + 150 * 8) + 3 * 8) + 34 * 8)]

1470
Tue Oct 27 11:20:46 2015 +0000
Author: Serban Constantinescu <1072549@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: b6d8bd3b_99f94bed
UUID: 56b5c1f6_5c4f9d53
Bytes: 40
I did mean ldp. Sorry for the confusion.

1531
Mon Oct 26 13:58:15 2015 +0000
Author: Serban Constantinescu <1072549@85c56323-6fa9-3386-8a01-6480fb634889>
UUID: 36b04d09_5b3e83f2
Bytes: 47
And with the above dmb this can be an dmb ishst

1531
Wed Oct 28 19:01:33 2015 +0000
Author: Hans Boehm <1042828@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: 36b04d09_5b3e83f2
UUID: 96cad9dc_e9d931e1
Bytes: 317
That's what Hiroshi started with.  This does seem faster for now, in a place where it matters.  We should probably revisit once we have a faster acquire load implementation.

I think we all agree that the acquire load would be cleaner. But in spite of my reputation for hating performance :-), I think that wins here.


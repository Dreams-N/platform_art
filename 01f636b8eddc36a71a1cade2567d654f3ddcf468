Revision: 01f636b8eddc36a71a1cade2567d654f3ddcf468
Patch-set: 1
File: runtime/arch/arm64/quick_entrypoints_arm64.S

1458:65-1461:72
Mon Nov 02 09:08:38 2015 +0000
Author: Nicolas Geoffray <1038443@85c56323-6fa9-3386-8a01-6480fb634889>
UUID: 569941f8_bffd9322
Bytes: 93
So this is a compiler issue, not a processor cache in the presence of multicore issue, right?

1458:65-1461:72
Mon Nov 02 10:17:52 2015 +0000
Author: Serban Constantinescu <1072549@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: 569941f8_bffd9322
UUID: 167c2956_85ede4e6
Bytes: 320
No it is not a compiler issues. It is a fake dependency between x3 and x2 that prevents the CPU from reordering the
#MIRROR_CLASS_STATUS_OFFSET and #MIRROR_CLASS_ACCESS_FLAGS_OFFSET loads to #MIRROR_CLASS_ACCESS_FLAGS_OFFSET and #MIRROR_CLASS_STATUS_OFFSET.

As mentioned in the comments a load-acquire would be cleaner.

1458:65-1461:72
Mon Nov 02 10:27:43 2015 +0000
Author: Nicolas Geoffray <1038443@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: 167c2956_85ede4e6
UUID: b688bda5_02ae2c05
Bytes: 864
So for my understanding, we worry about the situation:

Thread1 (executing this stub): load the access flags
Thread2 (executing the clinit): set the flags and initialize the class.
Thread1: load the status flags

Right?

But by loading the access flags, we have loaded into our CPU cache the page where the class is. So the read of the status flag will go through the cache. Still correct?

So I understand that if the threads have run on the same CPU, it is definitely a CPU reordering problem.

I'm also curious what happens if we do this dependency trick, but Thread1 and Thread2 run on two different cpus. Say Thread1 loads the status flag, but the access flags is not on the same page (is that possible?), but has been loaded somehow before in our cpu cache. Could it be that even after reading the status flag, reading the access flag could still be garbage?

1458:65-1461:72
Mon Nov 02 11:57:58 2015 +0000
Author: Vladimir Marko <1018108@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: b688bda5_02ae2c05
UUID: 167c2956_c548cca1
Bytes: 845
This situation we're concerned about is this:

  Thread 1 executing <clinit>():
    - [11] replace old access flags with new access flags,
    - [12] replace old status with new status,
  Thread 2 executing this stub:
    - [21] read status: reads new status,
    - [22] read access flags: may read old access flags!

Without proper synchronization the writes by one thread may become visible to another thread (executing on another core) in a different order. To prevent this memory visibility reordering we would normally give [12] release semantics (which we do) and give [21] acquire semantics. The CPU-specific hack here is a fake dependency between [21] and [22] that makes up for the absence of the acquire semantics on [21].

(Note that the status and access flags are not necessarily in the same page, much less in the same cache line.)

1458:65-1461:72
Mon Nov 02 12:09:49 2015 +0000
Author: Nicolas Geoffray <1038443@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: 167c2956_c548cca1
UUID: 569941f8_7f36aba9
Bytes: 250
Just discussed with Vladimir. I think the comment is confusing. For me it implies preventing instruction re-ordering, whereas it's really about memory system reordering (and all that is implied with CPU cache and multicore).

Serban, can you confirm?

1458:65-1461:72
Mon Nov 02 12:50:22 2015 +0000
Author: Serban Constantinescu <1072549@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: 167c2956_c548cca1
UUID: 166509c4_9d5c67db
Bytes: 276
Nicolas, to add to Vladimir's answer - page/ cache line locality does not really matter here, and we should not rely on it for such situations.

Here is my favourite presentation on memory ordering:
http://events.linuxfoundation.org/sites/events/files/slides/weak-to-weedy.pdf

1458:65-1461:72
Mon Nov 02 12:58:56 2015 +0000
Author: Serban Constantinescu <1072549@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: 569941f8_7f36aba9
UUID: f66795cb_9c7e299d
Bytes: 423
Yes, it prevents memory system reordering. We basically make sure that the CPU always executes the 2nd load (CLASS_ACCESS_FLAGS) after the first one (CLASS_STATUS) which for a weak memory model, such as ARM might be possible.

In the same time, on the producer side (clinit) we make sure that at the end of the clinit procedure all the memory operations are visible in the inner-sharable domain, by flushing the CPU caches.

1458:65-1461:72
Mon Nov 02 15:49:49 2015 +0000
Author: Nicolas Geoffray <1038443@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: f66795cb_9c7e299d
UUID: 968f39ad_613b7001
Bytes: 65
Where exactly do you do this (the producer side CPU cache flush)?

1458:65-1461:72
Mon Nov 02 17:35:58 2015 +0000
Author: Hans Boehm <1042828@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: 968f39ad_613b7001
UUID: 760e462a_2671e878
Bytes: 957
Class::SetStatus does a SetField32Volatile, which should do either a release store or a dmb ish before actually setting the status.

That should suffice. On a CPU, there should never be a reason to actually flush the cache for memory consistency between CPUs. To zeroth order approximation, the cache coherence protocol (MESI or the like) should basically ensure sufficient ordering for actual memory system (CPU data caches and DRAM) accesses.  The role of fences/barriers is usually primarily to prevent reordering due to out-of-order execution and store buffers.

My impression is that the above is a good mental model, though I've been told by hardware architects that it is not 100% correct.  But a full flush on a CPU cache is way too expensive to be practical for this kind of use.  (Although GPUs apparently do something along those lines.  And actual cache flushes become much more of an issue on systems with non-volatile byte-addressable memory.)

1458:65-1461:72
Mon Nov 02 18:13:19 2015 +0000
Author: Serban Constantinescu <1072549@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: 760e462a_2671e878
UUID: 3694cdc0_619d32d7
Bytes: 623
The code above should, at least in theory be sufficient for creating the fake data dependency.

However I wonder what do CPUs such as Denver do (or allowed to do).

E.g:
Can the sequence:
eor x3, x3, x3
add x2, x2, x3

be transformed into:
add x2, x2, 0 (probably even nop).

and thus the sequence:
lrd w3, [x2, #offset_1]
eor x3, x3, x3
add x2, x2, x3
ldr w3, [x2, #offset_2]

become:
ldr w3, [x2, offset_2]   (ooo execution)
ldr w3, [x2, offset_1]

I need to go ask the right people if this is permitted or not. To my understanding since there is an expected side-effect for each instruction (like pc++) it should not be.

1458:65-1461:72
Mon Nov 02 19:07:33 2015 +0000
Author: Hans Boehm <1042828@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: 3694cdc0_619d32d7
UUID: f6195673_7faaba47
Bytes: 200
According to the ARM spec, this is pretty clearly disallowed.  I looked it up again when this first came up.  (B2.7.2 in my version of the spec.)

I believe Denver handles this kind of case correctly.

1452:0-1464:21
Mon Oct 26 13:58:15 2015 +0000
Author: Serban Constantinescu <1072549@85c56323-6fa9-3386-8a01-6480fb634889>
UUID: b6b19df3_b73b8890
Bytes: 97
Load aquire seems a better solution to me. Alternatively DMB ISHLD after the ldr would also work.

1452:0-1464:21
Mon Oct 26 18:27:44 2015 +0000
Author: Hiroshi Yamauchi <1022530@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: b6b19df3_b73b8890
UUID: f6ceb575_2ad45e1b
Bytes: 161
My measurement indicated this 'fake dependence' approach was faster than the dmb ishld + dmb ishst approach (by ~10-20% on arm32 at least). Better in what sense?

1452:0-1464:21
Tue Oct 27 11:20:46 2015 +0000
Author: Serban Constantinescu <1072549@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: f6ceb575_2ad45e1b
UUID: f69a3588_e1924696
Bytes: 347
Load acquire and store release have a finer granularity when compared to their ldr/str + dmbs equivalents, regarding memory ordering.

Future CPU implementations might decide to exploit this and to optimise even further the acquire-release path.

Therefore the acuqire-release path seems better to me.

For curiosity what have you measure this on?

1452:0-1464:21
Tue Oct 27 17:26:43 2015 +0000
Author: Hiroshi Yamauchi <1022530@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: f69a3588_e1924696
UUID: 96df3923_dbccacc1
Bytes: 369
Serban, there are three things we are comparing here. 1) ldr + the 'fake dependence' eor/add + no dmb (as is in this CL currently), 2) ldra, 3) ldr+dmb ishld. Are you saying that 2) is better than 3) or that 2) and 3) are better than 1) or something else?

The measurement was on a Nexus 5, which uses the arm32 version of this code, where 1) was faster than 3) for me.

1452:0-1464:21
Thu Oct 29 11:50:59 2015 +0000
Author: Serban Constantinescu <1072549@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: 96df3923_dbccacc1
UUID: b6199d10_375f3851
Bytes: 468
Sorry for the confusion. What I am saying is that 2) should always be preferred over 3), and as I mentioned future CPU versions will probably optimise this even further.

The comparison between 1) and 2) is debatable. The best way of comparing is writing a very directed ubenchmark, and even so there are CPU variants out there that decided to implement 2) as 3) for simplicity.

Therefore I think 1), the variant that you are currently using is the best in this case.

1452:0-1464:21
Thu Oct 29 17:59:16 2015 +0000
Author: Hiroshi Yamauchi <1022530@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: b6199d10_375f3851
UUID: 769c85d8_07710a0d
Bytes: 15
Agreed. Thanks.

1470
Mon Oct 26 13:58:15 2015 +0000
Author: Serban Constantinescu <1072549@85c56323-6fa9-3386-8a01-6480fb634889>
UUID: 36920d67_6b7e819d
Bytes: 251
#if THREAD_LOCAL_ALLOC_STACK_END_OFFSET != (THREAD_LOCAL_ALLOC_STACK_TOP_OFFSET + __SIZEOF_POINTER__)
#error "The assumption below that we can use ldrd from the STACK_TOP is invalid."
#endif

ldrd, x3, x4, [xSELF, #THREAD_LOCAL_ALLOC_STACK_TOP_OFFSET]

1470
Mon Oct 26 18:27:44 2015 +0000
Author: Hiroshi Yamauchi <1022530@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: 36920d67_6b7e819d
UUID: 76d48537_70d04e53
Bytes: 31
Can ldrd load two 64-bit words?

1470
Mon Oct 26 18:50:30 2015 +0000
Author: Andreas Gampe <1041833@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: 76d48537_70d04e53
UUID: 16b509da_f4d9787c
Bytes: 26
Serban probably meant ldp.

1470
Mon Oct 26 22:15:44 2015 +0000
Author: Hiroshi Yamauchi <1022530@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: 16b509da_f4d9787c
UUID: b6d8bd3b_99f94bed
Bytes: 250
ldp does not seems to work as the offset is out of the supported range.

art/runtime/arch/arm64/quick_entrypoints_arm64.S:1474:23: error: index must be a multiple of 8 in range [-512, 504].
    ldp x3, x4, [x19, #(((128 + 150 * 8) + 3 * 8) + 34 * 8)]

1470
Tue Oct 27 11:20:46 2015 +0000
Author: Serban Constantinescu <1072549@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: b6d8bd3b_99f94bed
UUID: 56b5c1f6_5c4f9d53
Bytes: 40
I did mean ldp. Sorry for the confusion.

1531
Mon Oct 26 13:58:15 2015 +0000
Author: Serban Constantinescu <1072549@85c56323-6fa9-3386-8a01-6480fb634889>
UUID: 36b04d09_5b3e83f2
Bytes: 47
And with the above dmb this can be an dmb ishst

1531
Wed Oct 28 19:01:33 2015 +0000
Author: Hans Boehm <1042828@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: 36b04d09_5b3e83f2
UUID: 96cad9dc_e9d931e1
Bytes: 317
That's what Hiroshi started with.  This does seem faster for now, in a place where it matters.  We should probably revisit once we have a faster acquire load implementation.

I think we all agree that the acquire load would be cleaner. But in spite of my reputation for hating performance :-), I think that wins here.


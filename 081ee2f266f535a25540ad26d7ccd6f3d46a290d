Revision: 081ee2f266f535a25540ad26d7ccd6f3d46a290d
Patch-set: 1
File: compiler/optimizing/induction_var_analysis.cc

490:61-490:83
Mon Sep 07 14:01:14 2015 +0000
Author: Calin Juravle <1022077@85c56323-6fa9-3386-8a01-6480fb634889>
UUID: c4ae4a93_780d613f
Bytes: 109
Please use a more revealing name and add documentation. *New* will not be so *new* anymore after a few weeks.

490:61-490:83
Mon Sep 07 17:01:55 2015 +0000
Author: Aart Bik <1074526@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: c4ae4a93_780d613f
UUID: 6492fe15_ee687d02
Bytes: 194
? :-)

New is not because I wrote this code yesterday, but it denotes I am creating a new node, possibly simplified.

See L103-113 in the header, NewInvariantOp, NewInvariantFetch, NewInduction.

490:61-490:83
Mon Sep 07 17:07:25 2015 +0000
Author: Calin Juravle <1022077@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: 6492fe15_ee687d02
UUID: e4d42ed5_1a5bc120
Bytes: 71
arh, ok, my bad :)

The rest of the code uses CreateSomething though...

490:61-490:83
Mon Sep 07 17:25:13 2015 +0000
Author: Aart Bik <1074526@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: e4d42ed5_1a5bc120
UUID: 64159e82_679961b5
Bytes: 156
Ah, I see, I can rename them in Create if that is the common nomenclature. I also like it when teams use one style consistently, so we all read code easier.

493:5-493:52
Mon Sep 07 09:14:50 2015 +0000
Author: Nicolas Geoffray <1038443@85c56323-6fa9-3386-8a01-6480fb634889>
UUID: a4deb6f4_f5413029
Bytes: 29
Perform some light-weight....

493:5-493:52
Mon Sep 07 17:01:55 2015 +0000
Author: Aart Bik <1074526@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: a4deb6f4_f5413029
UUID: 44141a88_a4ccf74a
Bytes: 4
Done

496:0-529:3
Mon Sep 07 09:14:50 2015 +0000
Author: Nicolas Geoffray <1038443@85c56323-6fa9-3386-8a01-6480fb634889>
UUID: a4deb6f4_b54ba847
Bytes: 105
Do you actually see this in practice? I'd assume other optimization phases would take care of it already.

496:0-529:3
Mon Sep 07 17:01:55 2015 +0000
Author: Aart Bik <1074526@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: a4deb6f4_b54ba847
UUID: 240f267a_2c375219
Bytes: 421
Yes, the 1, 0, and probably -1 are very common in induction. Note that these nodes are not in the HIR yet. If they would be, indeed instruction simplification would kick in, which is why I only do some light weight here, I will rely on HIR simplification later. But avoiding some of the very obvious cases saves a ton of new nodes in memory during analysis (viz. x + 0 and 1 * x occur a lot, see the tests alone already).

496:0-529:3
Mon Sep 07 17:05:46 2015 +0000
Author: Nicolas Geoffray <1038443@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: 240f267a_2c375219
UUID: 24bd66ca_535b241f
Bytes: 109
My point is that you can rely on HIR simplification, as we are already doing it. The fewer code the better :)

496:0-529:3
Mon Sep 07 17:25:13 2015 +0000
Author: Aart Bik <1074526@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: 24bd66ca_535b241f
UUID: 6492fe15_ce37c116
Bytes: 258
I fully agree with that, which is why I did not have this earlier. But while working with it a bit, it seems a bit of a waste to have all those nodes in memory for nothing (also it makes debugging output easier to read, but that would not be my sole reason).

496:0-529:3
Mon Sep 07 17:27:13 2015 +0000
Author: Nicolas Geoffray <1038443@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: 6492fe15_ce37c116
UUID: a455d63a_9a44c912
Bytes: 153
But won't that memory only be there under your test? 

Realistically, in production, after we run the simplifier pass, you won't have those nodes, right?

496:0-529:3
Mon Sep 07 17:31:01 2015 +0000
Author: Aart Bik <1074526@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: a455d63a_9a44c912
UUID: 644d9e85_795b0120
Bytes: 396
No, this is the internal representation of normalized induction expressions. E.g. range analysis, but also loop optimization use these nodes to determine how the induction is formed.

I have a CL ready that does range analysis, and uses this in BCE. I can put that out as a WIP to give you a better idea on how this works. But in essence, the induction_ mapping is what is needed by later phases.

496:0-529:3
Mon Sep 07 17:33:32 2015 +0000
Author: Nicolas Geoffray <1038443@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: 644d9e85_795b0120
UUID: a455d63a_fa418500
Bytes: 166
Yes, I understand :-) What I'm saying is that those a + 0, a * 1 nodes, you'll never see them in production because the instruction simplifier will have removed them.

496:0-529:3
Mon Sep 07 17:40:19 2015 +0000
Author: Aart Bik <1074526@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: a455d63a_fa418500
UUID: 0484e2ca_974ea534
Bytes: 388
Put in the meanwhile, it adds to the memory footprint during analysis. Since we will pass induction_ mapping to next phases, having hundred  "100 * i + x" will take a lot less bytes than the same hundred "(100 * 1) * i + (x + 0)". So if you only care about the eventually generated code, then yes, but I guess we also care about how much memory the optimizing compiler itself uses, right?

496:0-529:3
Mon Sep 07 17:45:08 2015 +0000
Author: Nicolas Geoffray <1038443@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: 0484e2ca_974ea534
UUID: 2461e61f_39b5c7b8
Bytes: 208
Let's chat offline, this conversation is ending up like a dialogue of the deaf :-)

I'm not talking about the generated code. I'm taking about whether this induction pass will ever see, eg (1 * a) in the HIR.

496:0-529:3
Mon Sep 07 17:53:01 2015 +0000
Author: Aart Bik <1074526@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: 2461e61f_39b5c7b8
UUID: 6492fe15_4e43b179
Bytes: 383
Even if the incoming HIR is fully optimized (and it usually is), just by the nature of analysis, those + 0 and * 1 nodes are generated (otherwise I would have to simplify during analysis, making it even less desirable code).

Look at the tests, not a +0 or *1 in the incoming input. Yet, the analysis by its mechanical nature, generates a lot of those in the internal representation.

496:0-529:3
Mon Sep 07 19:53:20 2015 +0000
Author: Nicolas Geoffray <1038443@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: 6492fe15_4e43b179
UUID: a4deb6f4_f5aa90b9
Bytes: 85
I see. Do you have a Java equivalent that would lead to such internal representation?

496:0-529:3
Mon Sep 07 20:12:28 2015 +0000
Author: Aart Bik <1074526@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: a4deb6f4_f5aa90b9
UUID: 04cce27b_7db5504e
Bytes: 798
Any  

for (int i = 0; i < 100; i++) {
  
}

in Java will already represent the phi node a 1 * i + 0
(since 0 is the first value, and the stride is 1)
and the add node
i_2 = i_1 + 1

as 1 * i + (0 + 1)
(since it transfers the first representation over the + 1, so we add the 0 value).

If we need to special cases the transfer operations, we would get horrible convoluted code. But by adding just a few basic rules to the CreateXX() method we avoid the most common cases.

Note that I am generally fully in agreement with you, we should not have two simplifiers if one suffices (for all the good software engineering reasons).

It is just that a few lines of code at a very well-defined place will save a substantial amount of runtime internal representation, so I thought this would be worthwhile.

496:0-529:3
Mon Sep 07 20:14:37 2015 +0000
Author: Nicolas Geoffray <1038443@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: 04cce27b_7db5504e
UUID: c4ae4a93_9844f53b
Bytes: 14
I see, thanks!

